/*
PluginProcessor.cpp
ÃƒÂ ÃƒÂÃ‚ÂµÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â°Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¿Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â° Ãƒâ€˜Ã‚Â STEREO ÃƒÂÃ‚Â¸ ADSR ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â´ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¶ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¹
*/
#include "PluginProcessor.h"
#include "PluginEditor.h"
NoiseBasedSamplerAudioProcessor::NoiseBasedSamplerAudioProcessor()
#ifndef JucePlugin_PreferredChannelConfigurations
    : AudioProcessor(BusesProperties()
#if ! JucePlugin_IsMidiEffect
#if ! JucePlugin_IsSynth
        .withInput("Input", juce::AudioChannelSet::stereo(), true)
#endif
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)
#endif
    )
#endif
{
    auto scaleParameter = std::make_unique<juce::AudioParameterFloat>(
        "scale", "Scale",
        juce::NormalisableRange<float>(0.0f, 2.0f, 0.001f), 1.0f);
    auto offsetParameter = std::make_unique<juce::AudioParameterFloat>(
        "offset", "Offset",
        juce::NormalisableRange<float>(-0.5f, 0.5f, 0.0001f), 0.0f);
    auto seedParameter = std::make_unique<juce::AudioParameterFloat>(
        "seed", "Seed",
        juce::NormalisableRange<float>(1.0f, 99999.0f, 1.0f), 12345.0f);
    auto bitDepthParameter = std::make_unique<juce::AudioParameterInt>(
        "bitdepth", "Bit Depth", 1, 16, 16);
    auto attackParameter = std::make_unique<juce::AudioParameterFloat>(
        "attack", "Attack",
        juce::NormalisableRange<float>(0.001f, 2.0f, 0.001f, 0.3f), 0.01f);
    auto decayParameter = std::make_unique<juce::AudioParameterFloat>(
        "decay", "Decay",
        juce::NormalisableRange<float>(0.001f, 2.0f, 0.001f, 0.3f), 0.1f);
    auto sustainParameter = std::make_unique<juce::AudioParameterFloat>(
        "sustain", "Sustain",
        juce::NormalisableRange<float>(0.0f, 1.0f, 0.01f), 0.7f);
    auto releaseParameter = std::make_unique<juce::AudioParameterFloat>(
        "release", "Release",
        juce::NormalisableRange<float>(0.001f, 5.0f, 0.001f, 0.3f), 0.3f);
    auto panParameter = std::make_unique<juce::AudioParameterFloat>(
        "pan", "Pan",
        juce::NormalisableRange<float>(0.0f, 1.0f, 0.01f), 0.5f);

    // New tool parameters
    auto boostDbParameter = std::make_unique<juce::AudioParameterFloat>(
        "boostDb", "Boost",
        juce::NormalisableRange<float>(-20.0f, 20.0f, 0.1f), 0.0f);
    auto pitchShiftParameter = std::make_unique<juce::AudioParameterFloat>(
        "pitchShift", "Pitch",
        juce::NormalisableRange<float>(-12.0f, 12.0f, 0.1f), 0.0f);
    auto timeStretchParameter = std::make_unique<juce::AudioParameterFloat>(
        "timeStretch", "Stretch",
        juce::NormalisableRange<float>(0.25f, 4.0f, 0.01f), 1.0f);
    auto loopActiveParameter = std::make_unique<juce::AudioParameterBool>(
        "loopActive", "Loop", false);

    scaleParam = scaleParameter.get();
    offsetParam = offsetParameter.get();
    seedParam = seedParameter.get();
    bitDepthParam = bitDepthParameter.get();
    attackParam = attackParameter.get();
    decayParam = decayParameter.get();
    sustainParam = sustainParameter.get();
    releaseParam = releaseParameter.get();
    panParam = panParameter.get();

    // New tool parameters
    boostDbParam = boostDbParameter.get();
    pitchShiftParam = pitchShiftParameter.get();
    timeStretchParam = timeStretchParameter.get();
    loopActiveParam = loopActiveParameter.get();
    addParameter(scaleParameter.release());
    addParameter(offsetParameter.release());
    addParameter(seedParameter.release());
    addParameter(bitDepthParameter.release());
    addParameter(attackParameter.release());
    addParameter(decayParameter.release());
    addParameter(sustainParameter.release());
    addParameter(releaseParameter.release());
    addParameter(panParameter.release());

    // Add new tool parameters
    addParameter(boostDbParameter.release());
    addParameter(pitchShiftParameter.release());
    addParameter(timeStretchParameter.release());
    addParameter(loopActiveParameter.release());

    algorithmFileManager = std::make_unique<AlgorithmFileManager>();

    DBG("âœ… Processor initialized with async algorithm loading");

    projectManager = std::make_unique<ProjectManager>(*this);
    DBG("âœ… ProjectManager initialized");

    PluginVersion::printVersionInfo();
}
NoiseBasedSamplerAudioProcessor::~NoiseBasedSamplerAudioProcessor()
{

    // âœ… ADD AT THE BEGINNING
    if (projectManager && hasSampleLoaded())
    {
        DBG("ğŸ’¾ Auto-saving project before closing...");
        projectManager->saveCurrentProject();
    }

    // algorithmFileManager = std::make_unique<AlgorithmFileManager>(); - so far leave this line alone
    // Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ»ÑĞ±Ñ‹Ğµ async Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
    if (algorithmFileManager)
    {
        algorithmFileManager.reset();
    }
}
const juce::String NoiseBasedSamplerAudioProcessor::getName() const
{
    return JucePlugin_Name;
}
bool NoiseBasedSamplerAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
    return true;
#else
    return false;
#endif
}
bool NoiseBasedSamplerAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
    return true;
#else
    return false;
#endif
}
bool NoiseBasedSamplerAudioProcessor::isMidiEffect() const
{
#if JucePlugin_IsMidiEffect
    return true;
#else
    return false;
#endif
}
double NoiseBasedSamplerAudioProcessor::getTailLengthSeconds() const
{
    return 0.0;
}
int NoiseBasedSamplerAudioProcessor::getNumPrograms()
{
    return 1;
}
int NoiseBasedSamplerAudioProcessor::getCurrentProgram()
{
    return 0;
}
void NoiseBasedSamplerAudioProcessor::setCurrentProgram(int index)
{
    juce::ignoreUnused(index);
}
const juce::String NoiseBasedSamplerAudioProcessor::getProgramName(int index)
{
    juce::ignoreUnused(index);
    return {};
}
void NoiseBasedSamplerAudioProcessor::changeProgramName(int index, const juce::String& newName)
{
    juce::ignoreUnused(index, newName);
}
void NoiseBasedSamplerAudioProcessor::prepareToPlay(
    double sampleRate,
    int samplesPerBlock)
{
    juce::ignoreUnused(samplesPerBlock);

    const int numOutputChannels = getTotalNumOutputChannels();

    // ============================
    // SAMPLE RATE CHANGE HANDLING
    // ============================
    if (std::abs(currentSampleRate - sampleRate) > 0.1)
    {
        DBG("===========================================");
        DBG("SAMPLE RATE CHANGED");
        DBG("===========================================");
        DBG("Old: " + juce::String(currentSampleRate, 0) + " Hz");
        DBG("New: " + juce::String(sampleRate, 0) + " Hz");

        currentSampleRate = sampleRate;

        if (sampleLoaded && originalSample.getNumSamples() > 0)
        {
            const juce::ScopedLock sl(sampleLock);

            DBG("Re-analyzing sample for new sample rate...");

            indexDatabase.clearCache();
            featureExtractor.getPhaseVocoder().invalidateCache();
            resetFeaturesModificationFlag();

            featureData = featureExtractor.extractFeatures(
                originalSample,
                currentSampleRate
            );

            processSample();
            analyzeSpectralIndices();

            DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Sample re-analyzed for new sample rate");
            sampleRateChanged = true;
        }
        else
        {
            DBG("No sample loaded - only updating sample rate");
        }
    }
    else
    {
        currentSampleRate = sampleRate;
    }

    // ============================
    // ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ‚Â¥ SAMPLE PLAYER PREPARE
    // ============================
    samplePlayer.prepare(
        numOutputChannels,     // ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ‚Â¥ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬Â¢ 1
        sampleRate,
        samplesPerBlock
    );

    samplePlayer.setSampleRate(sampleRate);

    samplePlayer.setADSRParameters({
        attackParam->get(),
        decayParam->get(),
        sustainParam->get(),
        releaseParam->get()
        });

    samplePlayer.setPan(panParam->get());

    samplePlayer.setInterpolationMode(
        SamplePlayer::InterpolationMode::Cubic
    );
}

void NoiseBasedSamplerAudioProcessor::releaseResources()
{
    const juce::ScopedLock sl(sampleLock);
    samplePlayer.allNotesOff();
    DBG("Audio processor released");
}
#ifndef JucePlugin_PreferredChannelConfigurations
bool NoiseBasedSamplerAudioProcessor::isBusesLayoutSupported(const BusesLayout& layouts) const
{
#if JucePlugin_IsMidiEffect
    juce::ignoreUnused(layouts);
    return true;
#else
    if (layouts.getMainOutputChannelSet() != juce::AudioChannelSet::stereo())
        return false;
    return true;
#endif
}
#endif
void NoiseBasedSamplerAudioProcessor::processBlock(
    juce::AudioBuffer<float>& buffer,
    juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    const juce::ScopedLock sl(sampleLock);

    const int numChannels = buffer.getNumChannels();
    const int numSamples = buffer.getNumSamples();

    // ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ‚Â¥ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â€œÃƒÂÃ‚ÂÃƒÂÃ…Â¾: Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼, ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚Âµ SamplePlayer ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â·ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â¡ÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã¢â‚¬Â¹
    buffer.clear();

    // Envelope parameters
    samplePlayer.setADSRParameters({
        attackParam->get(),
        decayParam->get(),
        sustainParam->get(),
        releaseParam->get()
        });

    // Pan parameter for SamplePlayer
    samplePlayer.setPan(panParam->get());

    // MIDI (ÃƒÂÃ‚Â±ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¹)
    for (const auto metadata : midiMessages)
    {
        auto message = metadata.getMessage();

        if (message.isNoteOn())
        {
            samplePlayer.noteOn(
                message.getNoteNumber(),
                message.getFloatVelocity()
            );
        }
        else if (message.isNoteOff())
        {
            samplePlayer.noteOff(message.getNoteNumber());
        }
        else if (message.isAllNotesOff() || message.isAllSoundOff())
        {
            samplePlayer.allNotesOff();
        }
    }

    // ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ‚Â¥ ÃƒÂÃ…Â¡ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â®ÃƒÂÃ‚Â§ÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ…Â¾: SamplePlayer ÃƒÂ ÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬ÂÃƒÂÃ¢â‚¬Â¢ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ STEREO
    samplePlayer.renderNextBlock(buffer, 0, numSamples);

    // DEBUG: Check if SamplePlayer is producing audio
    static bool audioCheckDone = false;
    if (!audioCheckDone)
    {
        float rms = 0.0f;
        for (int ch = 0; ch < buffer.getNumChannels(); ++ch)
        {
            rms += buffer.getRMSLevel(ch, 0, buffer.getNumSamples());
        }
        rms /= buffer.getNumChannels();
        DBG("ğŸµ SamplePlayer RMS: " + juce::String(rms, 6));
        audioCheckDone = true;
    }

    // ğŸ”Š APPLY REAL-TIME EFFECTS FROM CMD TOOLS
    applyRealtimeEffects(buffer);

    // DEBUG: Check final output
    static bool outputCheckDone = false;
    if (!outputCheckDone)
    {
        float rms = 0.0f;
        for (int ch = 0; ch < buffer.getNumChannels(); ++ch)
        {
            rms += buffer.getRMSLevel(ch, 0, buffer.getNumSamples());
        }
        rms /= buffer.getNumChannels();
        DBG("ğŸ”Š Final Output RMS: " + juce::String(rms, 6));
        outputCheckDone = true;
    }

    // DEBUG: Log parameter values
    static int debugCounter = 0;
    if (debugCounter++ % 1000 == 0) // Log every 1000th buffer
    {
        DBG("ğŸ”Š DEBUG - Boost: " + juce::String(getBoostDb(), 1) + "dB" +
            " | Pitch: " + juce::String(getPitchShift(), 1) + "st" +
            " | Stretch: " + juce::String(getTimeStretch(), 2) + "x" +
            " | Loop: " + juce::String(isLoopActive() ? "ON" : "OFF"));
    }
}

bool NoiseBasedSamplerAudioProcessor::hasEditor() const
{
    return true;
}
juce::AudioProcessorEditor* NoiseBasedSamplerAudioProcessor::createEditor()
{
    return new NoiseBasedSamplerAudioProcessorEditor(*this);
}
void NoiseBasedSamplerAudioProcessor::getStateInformation(juce::MemoryBlock& destData)
{
    juce::MemoryOutputStream stream(destData, false);

    // ========== Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ©Ğ˜Ğ• ĞŸĞĞ ĞĞœĞ•Ğ¢Ğ Ğ« (ĞºĞ°Ğº Ğ±Ñ‹Ğ»Ğ¾) ==========
    stream.writeFloat(scaleParam->get());
    stream.writeFloat(offsetParam->get());
    stream.writeFloat(seedParam->get());
    stream.writeInt(bitDepthParam->get());
    stream.writeFloat(attackParam->get());
    stream.writeFloat(decayParam->get());
    stream.writeFloat(sustainParam->get());
    stream.writeFloat(releaseParam->get());
    stream.writeFloat(panParam->get());

    // ========== Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ©Ğ˜Ğ• ĞŸĞĞ¢Ğ¢Ğ•Ğ ĞĞ« (ĞºĞ°Ğº Ğ±Ñ‹Ğ»Ğ¾) ==========
    const juce::ScopedLock sl(sampleLock);
    stream.writeInt(static_cast<int>(storedPatterns.size()));

    for (const auto& pattern : storedPatterns)
    {
        stream.writeInt(pattern.patternId);
        stream.writeInt(pattern.occurrenceCount);
        stream.writeFloat(pattern.averageValue);
        stream.writeFloat(pattern.variance);

        stream.writeInt(static_cast<int>(pattern.values.size()));
        for (float val : pattern.values)
            stream.writeFloat(val);

        stream.writeInt(static_cast<int>(pattern.occurrencePositions.size()));
        for (int pos : pattern.occurrencePositions)
            stream.writeInt(pos);
    }

    // ========== âœ… ĞĞĞ’ĞĞ•: UI STATE (Ñ‡ĞµÑ€ĞµĞ· XML) ==========
    auto uiStateXml = std::unique_ptr<juce::XmlElement>(uiState.toXml());
    juce::String xmlString = uiStateXml->toString();

    // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ¸ ÑĞ°Ğ¼Ñƒ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
    stream.writeInt(xmlString.length());
    stream.writeString(xmlString);

    DBG("ğŸ’¾ State saved: " + juce::String(storedPatterns.size()) + " patterns + UI state + effects");
}
void NoiseBasedSamplerAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
    juce::MemoryInputStream stream(data, static_cast<size_t>(sizeInBytes), false);

    // ========== Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ©Ğ˜Ğ• ĞŸĞĞ ĞĞœĞ•Ğ¢Ğ Ğ« (ĞºĞ°Ğº Ğ±Ñ‹Ğ»Ğ¾) ==========
    *scaleParam = stream.readFloat();
    *offsetParam = stream.readFloat();
    *seedParam = stream.readFloat();
    *bitDepthParam = stream.readInt();

    if (stream.getPosition() < stream.getTotalLength())
    {
        *attackParam = stream.readFloat();
        *decayParam = stream.readFloat();
        *sustainParam = stream.readFloat();
        *releaseParam = stream.readFloat();
        *panParam = stream.readFloat();
    }

    // ========== Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ©Ğ˜Ğ• ĞŸĞĞ¢Ğ¢Ğ•Ğ ĞĞ« (ĞºĞ°Ğº Ğ±Ñ‹Ğ»Ğ¾) ==========
    if (stream.getPosition() < stream.getTotalLength())
    {
        const juce::ScopedLock sl(sampleLock);
        storedPatterns.clear();

        int numPatterns = stream.readInt();

        for (int i = 0; i < numPatterns; ++i)
        {
            if (stream.isExhausted())
                break;

            IndexPattern pattern;
            pattern.patternId = stream.readInt();
            pattern.occurrenceCount = stream.readInt();
            pattern.averageValue = stream.readFloat();
            pattern.variance = stream.readFloat();

            int numValues = stream.readInt();
            pattern.values.reserve(numValues);
            for (int j = 0; j < numValues; ++j)
                pattern.values.push_back(stream.readFloat());

            int numPositions = stream.readInt();
            pattern.occurrencePositions.reserve(numPositions);
            for (int j = 0; j < numPositions; ++j)
                pattern.occurrencePositions.push_back(stream.readInt());

            storedPatterns.push_back(pattern);
        }

        DBG("ğŸ“¥ State loaded: " + juce::String(storedPatterns.size()) + " patterns");
    }

    // ========== âœ… ĞĞĞ’ĞĞ•: UI STATE ==========
    if (stream.getPosition() < stream.getTotalLength())
    {
        int xmlLength = stream.readInt();

        if (xmlLength > 0 && xmlLength < 1000000) // Ğ¡Ğ°Ğ½Ğ¸Ñ‚Ğ¸-Ñ‡ĞµĞº
        {
            juce::String xmlString = stream.readString();

            auto uiStateXml = juce::XmlDocument::parse(xmlString);

            if (uiStateXml != nullptr)
            {
                uiState.fromXml(uiStateXml.get());
                DBG("âœ… UI State restored from save");
            }
        }
    }
}

void NoiseBasedSamplerAudioProcessor::loadSample(const juce::File& file)
{
    juce::AudioFormatManager formatManager;
    formatManager.registerBasicFormats();
    std::unique_ptr<juce::AudioFormatReader> reader(formatManager.createReaderFor(file));

    if (reader != nullptr)
    {
        const juce::ScopedLock sl(sampleLock);

        int numChannels = static_cast<int>(reader->numChannels);
        int numSamples = static_cast<int>(reader->lengthInSamples);

        DBG("===========================================");
        DBG("LOADING SAMPLE (LAZY MODE)");
        DBG("===========================================");
        DBG("File: " + file.getFileName());
        DBG("Channels: " + juce::String(numChannels));
        DBG("Samples: " + juce::String(numSamples));

        // Ã¢Å“â€¦ Ãâ€™Ã‘ÂÃÂµÃÂ³ÃÂ´ÃÂ° ÃÂ·ÃÂ°ÃÂ³Ã‘â‚¬Ã‘Æ’ÃÂ¶ÃÂ°ÃÂµÃÂ¼ ÃÂ² STEREO
        juce::AudioBuffer<float> loadedBuffer(2, numSamples);

        if (numChannels == 1)
        {
            juce::AudioBuffer<float> tempMono(1, numSamples);
            reader->read(&tempMono, 0, numSamples, 0, true, false);
            loadedBuffer.copyFrom(0, 0, tempMono, 0, 0, numSamples);
            loadedBuffer.copyFrom(1, 0, tempMono, 0, 0, numSamples);
            DBG("  Converted MONO Ã¢â€ â€™ STEREO");
        }
        else if (numChannels >= 2)
        {
            reader->read(&loadedBuffer, 0, numSamples, 0, true, true);
            DBG("  Loaded as STEREO");
        }

        // Ã¢Å“â€¦ ÃËœÃÂ½ÃÂ¸Ã‘â€ ÃÂ¸ÃÂ°ÃÂ»ÃÂ¸ÃÂ·ÃÂ¸Ã‘â‚¬Ã‘Æ’ÃÂµÃÂ¼ AudioStateManager
        audioState.loadSample(
            loadedBuffer,
            currentSampleRate,
            featureExtractor,
            indexDatabase
        );

        auto groundTruth = audioState.getGroundTruthAudio();
        DBG("  Ground truth channels: " + juce::String(groundTruth.getNumChannels()));

        juce::AudioBuffer<float> monoForAnalysis(1, groundTruth.getNumSamples());
        monoForAnalysis.copyFrom(0, 0, groundTruth, 0, 0, groundTruth.getNumSamples());

        // Ã¢Å“â€¦ ÃÅ¡Ã ÃËœÃÂ¢ÃËœÃÂ§ÃÂÃÅ¾: ÃËœÃ‘ÂÃÂ¿ÃÂ¾ÃÂ»Ã‘Å’ÃÂ·Ã‘Æ’ÃÂµÃÂ¼ Ãâ€˜ÃÂ«ÃÂ¡ÃÂ¢Ã ÃÂ«Ãâ„¢ extractAmplitudeOnly ÃÂ²ÃÂ¼ÃÂµÃ‘ÂÃ‘â€šÃÂ¾ extractFeatures!
        DBG("Ã°Å¸Å¡â‚¬ Starting FAST feature extraction (Amplitude only)...");

        auto startTime = juce::Time::getMillisecondCounterHiRes();

        featureData = featureExtractor.extractAmplitudeOnly(monoForAnalysis, currentSampleRate);

        auto endTime = juce::Time::getMillisecondCounterHiRes();
        double elapsed = endTime - startTime;

        DBG("Ã¢Å“â€¦ FAST extraction complete in " + juce::String(elapsed, 2) + " ms");
        DBG("   (Other indices will compute on-demand)");

        // ÃÅ¾ÃÂ±ÃÂ½ÃÂ¾ÃÂ²ÃÂ»Ã‘ÂÃÂµÃÂ¼ ÃÂ±Ã‘Æ’Ã‘â€ÃÂµÃ‘â‚¬Ã‘â€¹
        originalSample.makeCopyOf(groundTruth);
        outputBuffer.makeCopyOf(groundTruth);

        sampleLoaded = true;

        // Store original for effect system
        effectStateManager.setOriginalSample(originalSample);

        resetFeaturesModificationFlag();
        featureExtractor.getPhaseVocoder().invalidateCache();

        processSample();

        samplePlayer.setSample(outputBuffer);
        samplePlayer.setEffectStateManager(&effectStateManager);

        // âœ… Reset start/length to default when new sample loaded
        setSampleStartOffset(0.0f);   // 0% = no offset
        setSamplePlaybackLength(1.0f); // 100% = full length

        DBG("===========================================");
        DBG("Ã¢Å“â€¦ SAMPLE LOADED (LAZY MODE - INSTANT!)");
        DBG("===========================================");

        // âœ… AUTO-APPLY ACTIVE EFFECTS TO NEW SAMPLE
        if (effectStateManager.isTrimActive() ||
            effectStateManager.isNormalizeActive() ||
            effectStateManager.isReverseActive() ||
            effectStateManager.isBoostActive())
        {
            DBG("ğŸ”„ Auto-applying active effects to new sample...");
            applyEffectStack();
            DBG("âœ… Active effects applied!");
        }

    }
    if (projectManager) projectManager->markDirty();
}

void NoiseBasedSamplerAudioProcessor::setFeatureAmplitudeAt(int index, float value) {
    featureData.setAmplitudeAt(index, value);
    if (projectManager) projectManager->markDirty();
}

void NoiseBasedSamplerAudioProcessor::setFeatureFrequencyAt(int index, float value) {
    featureData.setFrequencyAt(index, value);
    if (projectManager) projectManager->markDirty();
}

/*
void applyEffectStack()
{
    if (!effectStateManager.hasOriginalSample())
        return;

    // Ã¢Å“â€¦ Start with ORIGINAL for TRIM, but apply other effects to current state
    juce::AudioBuffer<float> processedBuffer;

    if (effectStateManager.isTrimActive())
    {
        // TRIM needs original sample for boundaries
        effectStateManager.applyAllEffects(processedBuffer);
    }
    else
    {
        // Other effects work with current state
        processedBuffer.makeCopyOf(outputBuffer);

        // Apply REVERSE first (if active)
        if (effectStateManager.isReverseActive())
        {
            effectStateManager.applyReverse(processedBuffer);
        }

        // Then NORMALIZE
        effectStateManager.applyNormalize(processedBuffer);
    }

    if (processedBuffer.getNumSamples() == 0)
        return;

// Update all dependent systems
    outputBuffer.makeCopyOf(processedBuffer);
    originalSample.makeCopyOf(processedBuffer);  // âœ… Also update originalSample for visualization
    effectStateManager.setOriginalSample(originalSample);  // âœ… Keep EffectStateManager in sync
    samplePlayer.setSample(outputBuffer);
    samplePlayer.setEffectStateManager(&effectStateManager);

    // Re-extract features from processed audio
    juce::AudioBuffer<float> monoForAnalysis(1, processedBuffer.getNumSamples());
    monoForAnalysis.copyFrom(0, 0, processedBuffer, 0, 0, processedBuffer.getNumSamples());

    featureData = featureExtractor.extractAmplitudeOnly(monoForAnalysis, currentSampleRate);

    // âœ… Mark features as modified to prevent processSample() overwriting
    featuresModifiedByUser = true;

    DBG("ğŸ” REVERSE: Updated featureData from processedBuffer, featuresModifiedByUser = true");

    DBG("Ã¢Å“â€¦ Effect stack applied - " + juce::String(processedBuffer.getNumSamples()) + " samples");
}
*/
void NoiseBasedSamplerAudioProcessor::loadSampleFromBuffer(const juce::AudioBuffer<float>& buffer)
{
    if (buffer.getNumSamples() == 0)
        return;

    const juce::ScopedLock sl(sampleLock);

    int numChannels = buffer.getNumChannels();
    int numSamples = buffer.getNumSamples();

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬â„¢Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â³ÃƒÂÃ‚Â´ÃƒÂÃ‚Â° ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°ÃƒÂÃ‚Â³Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â¶ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â² stereo
    originalSample.setSize(2, numSamples, false, true, false);

    if (numChannels == 1)
    {
        // Mono ÃƒÂ¢Ã¢â‚¬ Ã¢â‚¬â„¢ copy to both channels
        originalSample.copyFrom(0, 0, buffer, 0, 0, numSamples);
        originalSample.copyFrom(1, 0, buffer, 0, 0, numSamples);
        // Store original for effect system
        effectStateManager.setOriginalSample(originalSample);
    }
    else if (numChannels >= 2)
    {
        // Stereo ÃƒÂ¢Ã¢â‚¬ Ã¢â‚¬â„¢ copy both channels
        originalSample.copyFrom(0, 0, buffer, 0, 0, numSamples);
        originalSample.copyFrom(1, 0, buffer, 1, 0, numSamples);
        // Store original for effect system
        effectStateManager.setOriginalSample(originalSample);
    }

    // âœ… Reset ALL effect states before setting new sample
    effectStateManager.setReverseActive(false);
    effectStateManager.setTrimActive(false);
    effectStateManager.setNormalizeActive(false);

    // âœ… Set original sample in effect manager FIRST
    effectStateManager.setOriginalSample(originalSample);

    // âœ… Create backup for reverse restoration AFTER setting original
    originalSampleBackup.makeCopyOf(originalSample);

    sampleLoaded = true;
    resetFeaturesModificationFlag();
    featureExtractor.getPhaseVocoder().invalidateCache();

    processSample();
    analyzeSpectralIndices();

    DBG("Sample loaded from buffer in STEREO: " + juce::String(numSamples) + " samples");
}

// ============================================================================
// ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¡ÃƒÂÃ…Â¸ÃƒÂ ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‹Å“ÃƒÂÃ¢â‚¬Â¢ #3: processSample() - ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂºÃƒÂÃ‚Â° ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Â¦ ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²
// ============================================================================

void NoiseBasedSamplerAudioProcessor::processSample()
{
    if (!sampleLoaded || originalSample.getNumSamples() == 0)
        return;

    int numSamples = originalSample.getNumSamples();
    int numChannels = originalSample.getNumChannels();  // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚Â¢ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¿ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã…â€™ = 2!

    DBG("Processing sample: " + juce::String(numChannels) + " channels, " +
        juce::String(numSamples) + " samples");

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Feature extraction ÃƒÂÃ‚Â½ÃƒÂÃ‚Â° LEFT ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Âµ (ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â²ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¸)
    if (!featuresModifiedByUser)
    {
        DBG("ğŸ” processSample(): Extracting features from originalSample (featuresModifiedByUser = false)");
        // ÃƒÃ‚Â§ÃƒÃ‚Â¾ÃƒÃ‚Â·ÃƒÃ‚Â´ÃƒÃ‚Â°Ãƒâ€˜Ã¢â‚¬ËœÃƒÃ‚Â¼ ÃƒÃ‚Â²Ãƒâ€˜Ã¢â€šÂ¬ÃƒÃ‚ÂµÃƒÃ‚Â¼ÃƒÃ‚ÂµÃƒÃ‚Â½ÃƒÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÃ‚Â¹ ÃƒÃ‚Â¼ÃƒÃ‚Â¾ÃƒÃ‚Â½ÃƒÃ‚Â¾ ÃƒÃ‚Â±Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ ÃƒÃ‚Â¸ÃƒÃ‚Â· ÃƒÃ‚Â»ÃƒÃ‚ÂµÃƒÃ‚Â²ÃƒÃ‚Â¾ÃƒÃ‚Â³ÃƒÃ‚Â¾ ÃƒÃ‚ÂºÃƒÃ‚Â°ÃƒÃ‚Â½ÃƒÃ‚Â°ÃƒÃ‚Â»ÃƒÃ‚Â°
        juce::AudioBuffer<float> monoForAnalysis(1, numSamples);
        monoForAnalysis.copyFrom(0, 0, originalSample, 0, 0, numSamples);

        featureData = featureExtractor.extractFeatures(monoForAnalysis, currentSampleRate);

        auto stats = featureData.calculateStatistics();
        DBG("Feature Stats (Left channel):");
        DBG("  Amplitude: " + juce::String(stats.minAmplitude, 3) + " to " +
            juce::String(stats.maxAmplitude, 3));
    }

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Noise generation - STEREO
    noiseBuffer.setSize(2, numSamples, false, true, false);  // 2 channels!
    noiseGenerator.setSeed(static_cast<uint64_t>(seedParam->get()));
    noiseGenerator.generateNoise(noiseBuffer);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Difference calculation - STEREO
    differenceEngine.calculateDifference(originalSample, noiseBuffer, differenceBuffer);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Reconstruction - STEREO
    float scale = scaleParam->get();
    float offset = offsetParam->get();
    int bitDepth = bitDepthParam->get();

    differenceEngine.reconstruct(noiseBuffer, differenceBuffer, reconstructedBuffer,
        scale, offset, bitDepth);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Output ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â playback - STEREO
    outputBuffer.setSize(2, numSamples, false, true, false);
    outputBuffer.makeCopyOf(reconstructedBuffer);

    samplePlayer.setSample(outputBuffer);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Sample processed in STEREO");
}
// latest version of applyFeatureChangestoSample ykwim
void NoiseBasedSamplerAudioProcessor::applyFeatureChangesToSample()
{
    if (featureData.getNumSamples() == 0)
        return;

    const juce::ScopedLock sl(sampleLock);

    DBG("===========================================");
    DBG("Ã°Å¸Å½Âµ APPLYING FEATURE CHANGES");
    DBG("===========================================");

    // Ã¢Å“â€¦ ÃÅ¡Ãâ€ºÃÂ®ÃÂ§Ãâ€¢Ãâ€™ÃÅ¾Ãâ€¢: ÃËœÃ‘ÂÃÂ¿ÃÂ¾ÃÂ»Ã‘Å’ÃÂ·Ã‘Æ’ÃÂµÃÂ¼ AudioStateManager ÃÂºÃÂ¾Ã‘â€šÃÂ¾Ã‘â‚¬Ã‘â€¹ÃÂ¹ Ã‘ÂÃÂ¾Ã‘â€¦Ã‘â‚¬ÃÂ°ÃÂ½ÃÂ¸Ã‘â€š Ã‘ÂÃ‘â€šÃÂµÃ‘â‚¬ÃÂµÃÂ¾
    audioState.applyFeatureChanges(
        featureData,
        currentSampleRate,
        indexDatabase,
        true
    );

    // ÃÅ¸ÃÂ¾ÃÂ»Ã‘Æ’Ã‘â€¡ÃÂ°ÃÂµÃÂ¼ Ã‘â‚¬ÃÂµÃÂ·Ã‘Æ’ÃÂ»Ã‘Å’Ã‘â€šÃÂ°Ã‘â€š
    auto groundTruth = audioState.getGroundTruthAudio();

    // Ã¢Å“â€¦ ÃÅ¸Ã ÃÅ¾Ãâ€™Ãâ€¢Ã ÃÅ¡ÃÂ: Ground truth ÃÂ´ÃÂ¾ÃÂ»ÃÂ¶ÃÂµÃÂ½ ÃÂ±Ã‘â€¹Ã‘â€šÃ‘Å’ ÃÂ² STEREO
    if (groundTruth.getNumChannels() < 2)
    {
        DBG("Ã¢ÂÅ’ ERROR: Ground truth is not STEREO!");
        return;
    }

    // ÃÅ¾ÃÂ±ÃÂ½ÃÂ¾ÃÂ²ÃÂ»Ã‘ÂÃÂµÃÂ¼ ÃÂ±Ã‘Æ’Ã‘â€ÃÂµÃ‘â‚¬Ã‘â€¹
    outputBuffer.makeCopyOf(groundTruth);
    originalSample.makeCopyOf(groundTruth);

    // âœ… ĞšĞĞĞ¡Ğ¢ĞĞĞ¢ĞĞ«Ğ• Ğ­Ğ¤Ğ¤Ğ•ĞšĞ¢Ğ«: ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ TRIM
    if (effectStateManager.isTrimActive())
    {
        DBG("ğŸ”§ Applying trim effect...");

        // Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑÑĞ¼Ğ¿Ğ» Ğ´Ğ»Ñ EffectStateManager
        effectStateManager.setOriginalSample(originalSample);

        // ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ trim (Ğ±ĞµĞ· normalize!)
        juce::AudioBuffer<float> processedBuffer;
        effectStateManager.applyAllEffects(processedBuffer);

        // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²ÑĞµ Ğ±ÑƒÑ„ĞµÑ€Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ¼
        outputBuffer.makeCopyOf(processedBuffer);
        originalSample.makeCopyOf(processedBuffer);

        DBG("âœ… Trim applied");
    }

    // âœ… REAL-TIME NORMALIZE: ĞŸĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ ĞŸĞĞ¡Ğ›Ğ• Ğ²ÑĞµÑ… Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
    if (effectStateManager.isNormalizeActive())
    {
        // âœ… ĞŸĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ gain Ğ¸Ğ· CURRENT output buffer
        float peak = 0.0f;
        const int numChannels = outputBuffer.getNumChannels();
        const int numSamples = outputBuffer.getNumSamples();

        for (int ch = 0; ch < numChannels; ++ch)
        {
            const float* data = outputBuffer.getReadPointer(ch);
            for (int i = 0; i < numSamples; ++i)
                peak = juce::jmax(peak, std::abs(data[i]));
        }

        if (peak > 0.0f)
        {
            const float targetLin = std::pow(10.0f, 0.0f / 20.0f); // 0 dB
            const float gain = targetLin / peak;

            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ gain Ğ² EffectStateManager
            effectStateManager.setNormalizeActive(true, 0.0f, gain);

            DBG("ğŸ›ï¸ Real-time normalize: peak=" + juce::String(peak, 4) + " gain=" + juce::String(gain, 4));

            // ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ gain
            outputBuffer.applyGain(gain);

            DBG("âœ… Real-time normalize applied");
        }
    }

    // âœ… Ğ’ÑĞµĞ³Ğ´Ğ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ player
    samplePlayer.allNotesOff();
    samplePlayer.setSample(outputBuffer);

    resetFeaturesModificationFlag();

    // Ãâ€™ÃÂµÃ‘â‚¬ÃÂ¸Ã‘â€ÃÂ¸ÃÂºÃÂ°Ã‘â€ ÃÂ¸Ã‘Â
    const float* left = outputBuffer.getReadPointer(0);
    const float* right = outputBuffer.getReadPointer(1);

    int stereoSamples = 0;
    for (int i = 0; i < outputBuffer.getNumSamples(); ++i)
    {
        if (std::abs(left[i] - right[i]) > 0.0001f)
            stereoSamples++;
    }

    float stereoPercent = (stereoSamples * 100.0f) / outputBuffer.getNumSamples();

    DBG("Ã¢Å“â€¦ Features applied!");
    DBG("   Channels: " + juce::String(outputBuffer.getNumChannels()));
    DBG("   Stereo content: " + juce::String(stereoPercent, 1) + "%");
    DBG("===========================================");
}

/*
void NoiseBasedSamplerAudioProcessor::applyFeatureChangesToSample()
{
    if (featureData.getNumSamples() == 0)
        return;

    const juce::ScopedLock sl(sampleLock);

    DBG("===========================================");
    DBG("ÃƒÂ°Ã…Â¸Ã…Â½Ã‚Âµ APPLYING FEATURE CHANGES");
    DBG("===========================================");

    int numSamples = featureData.getNumSamples();

    // STEP 1: ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â·ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â· features
    juce::AudioBuffer<float> synthesizedStereo(2, numSamples);
    featureData.applyToAudioBuffer(synthesizedStereo, currentSampleRate);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Step 1: Features ÃƒÂ¢Ã¢â‚¬ Ã¢â‚¬â„¢ Audio synthesis complete");

    // STEP 2: ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ originalSample (ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Â¦Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â)
    originalSample.setSize(2, numSamples, false, true, false);
    originalSample.copyFrom(0, 0, synthesizedStereo, 0, 0, numSamples);
    originalSample.copyFrom(1, 0, synthesizedStereo, 1, 0, numSamples);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Step 2: Updated originalSample");

    // STEP 3: ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ - ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ outputBuffer
    outputBuffer.setSize(2, numSamples, false, true, false);
    outputBuffer.makeCopyOf(synthesizedStereo);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Step 3: Updated outputBuffer (ground truth)");

    // STEP 4: ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ player
    samplePlayer.setSample(outputBuffer);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Step 4: Player updated");

    // STEP 5: ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢ - ÃƒÂÃ‹Å“ÃƒÂÃ‚Â½ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ spectral cache
    // ÃƒÂÃ‚Â¢ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¿ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã…â€™ spectral indices Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸, Ãƒâ€˜Ã¢â‚¬Å¡.ÃƒÂÃ‚Âº. ÃƒÂÃ‚Â°Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã…â€™
    // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚Â´Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã…Â½Ãƒâ€˜Ã¢â‚¬Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ "Analyze Indices" ÃƒÂÃ‚Â±Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Å¡ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾ÃƒÂÃ‚Â·ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â° ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â±ÃƒÂÃ‚Â°ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°

    // ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â«ÃƒÂÃ¢â‚¬â€ÃƒÂÃ‚Â«ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ…â€œ analyzeSpectralIndices() ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚ÂºÃƒÂÃ‚Â¸!
    // ÃƒÂÃ…Â¸ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒâ€˜Ã‹â€ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡ ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â´ÃƒÂÃ‚Â° ÃƒÂÃ‚Â¿ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Âµ-ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™

    DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Spectral indices cache is now STALE");
    DBG("   Click 'Analyze Indices' to re-analyze");

    DBG("===========================================");
    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ FEATURE CHANGES APPLIED!");
    DBG("===========================================");

    resetFeaturesModificationFlag();
}
*/

void NoiseBasedSamplerAudioProcessor::exportModifiedSample(const juce::File& file)
{
    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¡ÃƒÂÃ…Â¸ÃƒÂ ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‹Å“ÃƒÂÃ¢â‚¬Â¢: ÃƒÂÃ‚Â­ÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ outputBuffer (ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ originalSample)
    if (!sampleLoaded || outputBuffer.getNumSamples() == 0)
        return;

    juce::WavAudioFormat wavFormat;

    if (auto fileStream = file.createOutputStream())
    {
        if (auto writer = wavFormat.createWriterFor(
            fileStream.release(),
            currentSampleRate,
            outputBuffer.getNumChannels(),  // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ outputBuffer
            32,
            {},
            0))
        {
            writer->writeFromAudioSampleBuffer(outputBuffer, 0,  // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ outputBuffer
                outputBuffer.getNumSamples());
            delete writer;
            DBG("Exported modified sample to: " + file.getFullPathName());
        }
    }
}
void NoiseBasedSamplerAudioProcessor::exportDifferenceData(const juce::File& file)
{
    if (!sampleLoaded || differenceBuffer.getNumSamples() == 0)
        return;
    auto stats = differenceEngine.calculateStatistics(differenceBuffer);
    juce::DynamicObject::Ptr jsonData = new juce::DynamicObject();
    jsonData->setProperty("version", "1.0");
    jsonData->setProperty("seed", static_cast<int>(noiseGenerator.getSeed()));
    jsonData->setProperty("length", differenceBuffer.getNumSamples());
    jsonData->setProperty("sampleRate", currentSampleRate);
    juce::DynamicObject::Ptr params = new juce::DynamicObject();
    params->setProperty("scale", scaleParam->get());
    params->setProperty("offset", offsetParam->get());
    params->setProperty("bitDepth", bitDepthParam->get());
    jsonData->setProperty("parameters", params.get());
    juce::DynamicObject::Ptr statsObj = new juce::DynamicObject();
    statsObj->setProperty("min", stats.min);
    statsObj->setProperty("max", stats.max);
    statsObj->setProperty("mean", stats.mean);
    statsObj->setProperty("rms", stats.rms);
    jsonData->setProperty("statistics", statsObj.get());
    juce::Array<juce::var> dataArray;
    auto* data = differenceBuffer.getReadPointer(0);
    int samplesToExport = std::min(1000, differenceBuffer.getNumSamples());
    for (int i = 0; i < samplesToExport; ++i)
    {
        dataArray.add(data[i]);
    }
    jsonData->setProperty("differenceData", dataArray);
    juce::var jsonVar(jsonData.get());
    juce::String jsonString = juce::JSON::toString(jsonVar, true);
    file.replaceWithText(jsonString);
    DBG("Exported difference data to: " + file.getFullPathName());
}

// ============================================================================
// Sample-level utility operations (trim + normalize)
// ============================================================================

void NoiseBasedSamplerAudioProcessor::trimSilence(float thresholdDb)
{
    const juce::ScopedLock sl(sampleLock);

    if (!sampleLoaded || originalSample.getNumSamples() == 0)
        return;

    const int numChannels = originalSample.getNumChannels();
    const int numSamples = originalSample.getNumSamples();

    const float thresholdLin = std::pow(10.0f, thresholdDb / 20.0f); // e.g. -60 dB -> ~0.001

    int start = 0;
    int end = numSamples - 1;

    // Find first non-silent sample from the left
    bool foundStart = false;
    for (int i = 0; i < numSamples; ++i)
    {
        float maxAtSample = 0.0f;
        for (int ch = 0; ch < numChannels; ++ch)
            maxAtSample = juce::jmax(maxAtSample,
                std::abs(originalSample.getSample(ch, i)));

        if (maxAtSample >= thresholdLin)
        {
            start = i;
            foundStart = true;
            break;
        }
    }

    // If nothing above threshold, do nothing
    if (!foundStart)
        return;

    // Find first non-silent sample from the right
    for (int i = numSamples - 1; i >= 0; --i)
    {
        float maxAtSample = 0.0f;
        for (int ch = 0; ch < numChannels; ++ch)
            maxAtSample = juce::jmax(maxAtSample,
                std::abs(originalSample.getSample(ch, i)));

        if (maxAtSample >= thresholdLin)
        {
            end = i;
            break;
        }
    }

    const int trimmedLength = end - start + 1;
    if (trimmedLength <= 0 || trimmedLength == numSamples)
        return;

    juce::AudioBuffer<float> trimmed(numChannels, trimmedLength);

    for (int ch = 0; ch < numChannels; ++ch)
        trimmed.copyFrom(ch, 0, originalSample, ch, start, trimmedLength);

    DBG("âœ‚ï¸ TrimSilence: " + juce::String(numSamples) + " -> " +
        juce::String(trimmedLength) + " samples");

    // Reuse standard loading path to update all dependent buffers/player/state
    loadSampleFromBuffer(trimmed);
}

void NoiseBasedSamplerAudioProcessor::normalizeSample(float targetDb)
{
    const juce::ScopedLock sl(sampleLock);

    if (!sampleLoaded || originalSample.getNumSamples() == 0)
        return;

    const int numChannels = originalSample.getNumChannels();
    const int numSamples = originalSample.getNumSamples();

    // Find peak amplitude
    float peak = 0.0f;
    for (int ch = 0; ch < numChannels; ++ch)
    {
        const float* data = originalSample.getReadPointer(ch);
        for (int i = 0; i < numSamples; ++i)
            peak = juce::jmax(peak, std::abs(data[i]));
    }

    if (peak <= 0.0f)
        return;

    const float targetLin = std::pow(10.0f, targetDb / 20.0f); // 0 dB -> 1.0
    const float gain = targetLin / peak;

    juce::AudioBuffer<float> normalized;
    normalized.makeCopyOf(originalSample);

    normalized.applyGain(gain);

    DBG("ğŸ“ˆ Normalize: peak=" + juce::String(peak, 4) +
        " -> target=" + juce::String(targetLin, 4) +
        ", gain=" + juce::String(gain, 4));

    loadSampleFromBuffer(normalized);
}

void NoiseBasedSamplerAudioProcessor::analyzeSpectralIndices()
{
    const juce::ScopedLock sl(sampleLock);

    if (!sampleLoaded)
    {
        DBG("ÃƒÂ¢Ã‚ÂÃ…â€™ Cannot analyze: no sample loaded");
        return;
    }

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¡ÃƒÂÃ…Â¸ÃƒÂ ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‹Å“ÃƒÂÃ¢â‚¬Â¢: ÃƒÂÃ‹Å“Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¢ÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ…Â¡ÃƒÂÃ‚Â£ÃƒÂÃ‚Â©ÃƒÂÃ‹Å“ÃƒÂÃ¢â€Â¢ outputBuffer ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™
    const juce::AudioBuffer<float>* audioToAnalyze = nullptr;

    if (outputBuffer.getNumSamples() > 0)
    {
        audioToAnalyze = &outputBuffer;
        DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Analyzing CURRENT outputBuffer (includes all edits)");
    }
    else if (originalSample.getNumSamples() > 0)
    {
        audioToAnalyze = &originalSample;
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Analyzing originalSample (no edits yet)");
    }
    else
    {
        DBG("ÃƒÂ¢Ã‚ÂÃ…â€™ No audio to analyze!");
        return;
    }

    DBG("===========================================");
    DBG("ANALYZING SPECTRAL INDICES (CURRENT STATE)");
    DBG("===========================================");
    DBG("Samples: " + juce::String(audioToAnalyze->getNumSamples()));

    // ÃƒÂÃ‚ÂÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Âµ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Âµ
    indexDatabase.analyzeSample(*audioToAnalyze, currentSampleRate);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â±Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚Â³ ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¹
    // (Ãƒâ€˜Ã¢â‚¬Å¡.ÃƒÂÃ‚Âº. Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â±ÃƒÂÃ‚Â°ÃƒÂÃ‚Â·ÃƒÂÃ‚Â° ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Å¡ Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â°Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾)
    indicesModified = false;

    auto stats = indexDatabase.getStatistics();
    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Analysis complete:");
    DBG("  Overview indices: " + juce::String(stats.overviewTotalIndices));
    DBG("  Transients: " + juce::String(stats.totalTransients));
    DBG("  Peaks: " + juce::String(stats.totalPeaks));
    DBG("===========================================");
}

void NoiseBasedSamplerAudioProcessor::searchForPatterns()
{
    if (!sampleLoaded || differenceBuffer.getNumSamples() == 0)
    {
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Cannot search patterns: no sample loaded");
        return;
    }
    DBG("ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ‚Â Starting pattern search...");
    DBG("Difference buffer size: " + juce::String(differenceBuffer.getNumSamples()));
    DBG("Sample rate: " + juce::String(currentSampleRate));
    auto* data = differenceBuffer.getReadPointer(0);
    float minVal = *std::min_element(data, data + differenceBuffer.getNumSamples());
    float maxVal = *std::max_element(data, data + differenceBuffer.getNumSamples());
    DBG("Difference range: " + juce::String(minVal, 4) + " to " + juce::String(maxVal, 4));
    patternLibrary.clearPatterns();
    std::vector<Pattern> foundPatterns = patternDetector.detectPatterns(
        differenceBuffer,
        currentSampleRate,
        &indexDatabase
    );
    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Found " + juce::String(foundPatterns.size()) + " patterns");
    patternLibrary.addPatterns(foundPatterns);
}
void NoiseBasedSamplerAudioProcessor::applyPatternToSample(Pattern& pattern, float intensity)
{
    if (!sampleLoaded || differenceBuffer.getNumSamples() == 0)
        return;
    pattern.applyToBuffer(differenceBuffer, intensity);
    float scale = scaleParam->get();
    float offset = offsetParam->get();
    int bitDepth = bitDepthParam->get();
    differenceEngine.reconstruct(noiseBuffer, differenceBuffer, reconstructedBuffer,
        scale, offset, bitDepth);
    samplePlayer.setSample(reconstructedBuffer);
    DBG("Applied pattern modifications to sample");
}

void NoiseBasedSamplerAudioProcessor::synthesizeFromSpectralIndices(
    const SpectralIndexData& indices,
    juce::AudioBuffer<float>& outputBuffer)
{
    if (indices.getNumFrames() == 0 || outputBuffer.getNumSamples() == 0)
    {
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Cannot synthesize: empty data");
        return;
    }

    DBG("ÃƒÂ°Ã…Â¸Ã…Â½Ã‚Âµ ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ…Â¾ÃƒÂÃ…Â¡ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ‚ÂÃƒÂÃ‚Â«ÃƒÂÃ¢â€Â¢ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· spectral indices...");

    // ÃƒÂÃ…Â¸ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ…Â¡ÃƒÂÃ…Â¾ ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ bins
    auto modifiedBins = indices.getAllModifiedBins();

    if (modifiedBins.empty())
    {
        DBG("  No modifications");
        return;
    }

    DBG("  Frames: " + juce::String(indices.getNumFrames()));
    DBG("  Bins: " + juce::String(indices.getNumBins()));
    DBG("  Modified bins: " + juce::String(modifiedBins.size()));

    // ÃƒÂÃ¢â‚¬Å“Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¹ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â²ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸
    std::map<int, std::vector<SpectralIndexData::ModifiedBinInfo>> modsByFrame;

    for (const auto& binInfo : modifiedBins)
    {
        modsByFrame[binInfo.frameIdx].push_back(binInfo);
    }

    DBG("  Modified frames: " + juce::String(modsByFrame.size()));

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚Â£ÃƒÂÃ…â€œÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‚Â¬ÃƒÂÃ‚Â¨ÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã‹â€ ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¹ ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸
    int windowSize = 512;  // ÃƒÂÃ¢â‚¬ËœÃƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ 1024, Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¿ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã…â€™ ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Â°Ãƒâ€˜Ã¢â‚¬Ëœ ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã‹â€ ÃƒÂÃ‚Âµ
    int halfWindow = windowSize / 2;

    // Hann window
    std::vector<float> window(windowSize);
    for (int i = 0; i < windowSize; ++i)
    {
        window[i] = 0.5f * (1.0f - std::cos(
            2.0f * juce::MathConstants<float>::pi * i / (windowSize - 1)));
    }

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢: ÃƒÂÃ…Â¾Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¶ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ peak contributions ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â soft limiting
    std::vector<float> localPeaks(outputBuffer.getNumSamples(), 0.0f);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â Ãƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¹ÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â·ÃƒÂÃ‚Â° Ãƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¹ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼
    for (const auto& [frameIdx, frameMods] : modsByFrame)
    {
        const auto& frame = indices.getFrame(frameIdx);
        float timePosition = frame.timePosition;

        int samplePos = static_cast<int>(timePosition * currentSampleRate);

        if (samplePos < 0 || samplePos >= outputBuffer.getNumSamples())
            continue;

        // ÃƒÂÃ¢â‚¬ÂÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â¶ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ modified bin ÃƒÂÃ‚Â² Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¹ÃƒÂÃ‚Â¼ÃƒÂÃ‚Âµ
        for (const auto& binInfo : frameMods)
        {
            auto modifiedIndex = indices.getIndex(frameIdx, binInfo.binIdx);

            // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ…Â¾ÃƒÂÃ…Â¡ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Âµ: ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â° magnitude
            float magnitudeDelta = modifiedIndex.magnitude -
                modifiedIndex.originalMagnitude;

            if (std::abs(magnitudeDelta) < 0.0001f)
                continue;

            float frequency = binInfo.frequency;
            float phase = modifiedIndex.phase;

            // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â·ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚Â ÃƒÂÃ…â€œÃƒÂÃ¢â‚¬Â¢ÃƒÂÃ‚ÂÃƒÂÃ‚Â¬ÃƒÂÃ‚Â¨ÃƒÂÃ‹Å“ÃƒÂÃ…â€œ ÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼ (ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã‹â€ ÃƒÂÃ‚Âµ ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸)
            for (int i = -halfWindow; i < halfWindow; ++i)
            {
                int targetSample = samplePos + i;
                if (targetSample < 0 || targetSample >= outputBuffer.getNumSamples())
                    continue;

                // Hann window ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸
                float windowValue = window[i + halfWindow];

                // ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â½ÃƒÂÃ‚Â° Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â°Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Âµ bin
                float t = i / static_cast<float>(currentSampleRate);
                float sinValue = std::sin(
                    2.0f * juce::MathConstants<float>::pi * frequency * t + phase);

                // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ…Â¾ÃƒÂÃ…Â¡ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Âµ: ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼/ÃƒÂÃ‚Â²Ãƒâ€˜Ã¢â‚¬Â¹Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã†â€™
                float contribution = magnitudeDelta * sinValue * windowValue;

                // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢: ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â¹ soft limiting per-sample
                // ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â³ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¹ ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¸ ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¼Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â³ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Âµ ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Âµ
                float absContribution = std::abs(contribution);

                // Soft saturation ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™Ãƒâ€˜Ã‹â€ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Â¦ ÃƒÂÃ‚Â²ÃƒÂÃ‚ÂºÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â² (> 0.5)
                if (absContribution > 0.5f)
                {
                    float sign = (contribution > 0.0f) ? 1.0f : -1.0f;
                    // Tanh-like soft saturation
                    contribution = sign * (0.5f + std::tanh((absContribution - 0.5f) * 2.0f) * 0.3f);
                }

                // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Âº ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼
                for (int ch = 0; ch < outputBuffer.getNumChannels(); ++ch)
                {
                    float* channelData = outputBuffer.getWritePointer(ch);
                    channelData[targetSample] += contribution;

                    // ÃƒÂÃ…Â¾Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¶ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¸
                    localPeaks[targetSample] = juce::jmax(localPeaks[targetSample],
                        std::abs(channelData[targetSample]));
                }
            }
        }
    }

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‚Â£ÃƒÂÃ‚Â±Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â° ÃƒÂÃ¢â‚¬Å“ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬ËœÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ‚ÂÃƒÂÃ‚ÂÃƒÂÃ‚Â¯ ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â!
    // ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Ëœ - Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¿Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂºÃƒÂÃ‚Â° Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹Ãƒâ€˜Ã¢â‚¬Â¦ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²

    // ÃƒÂÃ‚Â¡Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒâ€˜Ã†â€™
    float maxPeak = 0.0f;
    int extremePeaks = 0;

    for (int i = 0; i < outputBuffer.getNumSamples(); ++i)
    {
        if (localPeaks[i] > maxPeak)
            maxPeak = localPeaks[i];

        if (localPeaks[i] > 0.99f)
            extremePeaks++;
    }

    DBG("  Max peak: " + juce::String(maxPeak, 3));
    DBG("  Extreme peaks: " + juce::String(extremePeaks));

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚ÂÃƒÂÃ‚Â¯ ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Å“ÃƒÂÃ‹Å“ÃƒÂÃ…Â¡ÃƒÂÃ‚Â: ÃƒÂÃ‚Â¢ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ ÃƒÂÃ…â€œÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Å“ÃƒÂÃ…Â¾ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹Ãƒâ€˜Ã¢â‚¬Â¦ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Â² (> 1% Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²)
    if (extremePeaks > outputBuffer.getNumSamples() / 100)
    {
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Applying LOCALIZED soft limiter to extreme peaks only");

        // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ soft limiting ÃƒÂÃ‚Â¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¬ÃƒÂÃ…Â¡ÃƒÂÃ…Â¾ ÃƒÂÃ‚Âº Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â»ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¸
        for (int ch = 0; ch < outputBuffer.getNumChannels(); ++ch)
        {
            float* channelData = outputBuffer.getWritePointer(ch);

            for (int i = 0; i < outputBuffer.getNumSamples(); ++i)
            {
                // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Å¡ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â» Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â³Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¹
                if (std::abs(channelData[i]) > 0.95f)
                {
                    float sign = (channelData[i] > 0.0f) ? 1.0f : -1.0f;
                    float absVal = std::abs(channelData[i]);

                    // Soft knee compression ÃƒÂÃ‚Â²Ãƒâ€˜Ã¢â‚¬Â¹Ãƒâ€˜Ã‹â€ ÃƒÂÃ‚Âµ 0.95
                    if (absVal > 0.95f)
                    {
                        float excess = absVal - 0.95f;
                        // ÃƒÂÃ…â€œÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â³ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚Âµ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¶ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Âµ Ãƒâ€˜Ã‚Â ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¾Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¼ 0.3
                        float compressed = 0.95f + excess * 0.3f;
                        channelData[i] = sign * juce::jlimit(0.0f, 1.0f, compressed);
                    }
                }
            }
        }

        // ÃƒÂÃ…Â¸ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚Âµ limiting
        maxPeak = 0.0f;
        for (int ch = 0; ch < outputBuffer.getNumChannels(); ++ch)
        {
            const float* channelData = outputBuffer.getReadPointer(ch);
            for (int i = 0; i < outputBuffer.getNumSamples(); ++i)
            {
                maxPeak = juce::jmax(maxPeak, std::abs(channelData[i]));
            }
        }
    }

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ‚Â¾ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â¹ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã‹â€ Ãƒâ€˜Ã¢â‚¬ËœÃƒÂÃ‚Â½!");
    DBG("   Final max peak: " + juce::String(maxPeak, 3));
    DBG("   Original audio PRESERVED everywhere except modified regions");
}

void NoiseBasedSamplerAudioProcessor::removeFeatureSamples(int startSample, int endSample)
{
    const juce::ScopedLock sl(sampleLock);

    if (!hasFeatureData() || startSample < 0 || endSample >= featureData.getNumSamples())
    {
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â Cannot remove samples: invalid range or no data");
        return;
    }

    if (startSample > endSample)
    {
        std::swap(startSample, endSample);
    }

    int numToRemove = endSample - startSample + 1;
    int numSamples = featureData.getNumSamples();
    int newNumSamples = numSamples - numToRemove;

    if (newNumSamples <= 0)
    {
        // ÃƒÂÃ‚Â£ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â
        featureData = FeatureData();
        originalSample.setSize(2, 0);
        originalSampleBackup.setSize(2, 0);
        outputBuffer.setSize(2, 0);
        samplePlayer.setSample(outputBuffer);

        DBG("ÃƒÂ°Ã…Â¸Ã¢â‚¬â€Ã¢â‚¬ËœÃƒÂ¯Ã‚Â¸Ã‚Â All samples removed - audio is now empty");
        return;
    }

    DBG("===========================================");
    DBG("REMOVING SAMPLES FROM TIMELINE");
    DBG("===========================================");
    DBG("Removing samples: " + juce::String(startSample) + " to " + juce::String(endSample));
    DBG("Total to remove: " + juce::String(numToRemove));
    DBG("New length: " + juce::String(newNumSamples) + " samples");

    // 1ÃƒÂ¯Ã‚Â¸Ã‚ÂÃƒÂ¢Ã†â€™Ã‚Â£ ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â·ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ËœÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â¹ FeatureData ÃƒÂÃ‚Â±ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã¢â‚¬ËœÃƒÂÃ‚Â½ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â³ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°
    FeatureData newFeatures;
    newFeatures.setSize(newNumSamples);

    // ÃƒÂÃ…Â¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â»Ãƒâ€˜Ã¢â‚¬Â¹ ÃƒÂÃ¢â‚¬ÂÃƒÂÃ…Â¾ Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â³ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°
    for (int i = 0; i < startSample; ++i)
    {
        newFeatures[i] = featureData[i];
    }

    // ÃƒÂÃ…Â¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â»Ãƒâ€˜Ã¢â‚¬Â¹ ÃƒÂÃ…Â¸ÃƒÂÃ…Â¾ÃƒÂÃ‚Â¡ÃƒÂÃ¢â‚¬ÂºÃƒÂÃ¢â‚¬Â¢ Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â³ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°
    for (int i = endSample + 1; i < numSamples; ++i)
    {
        newFeatures[i - numToRemove] = featureData[i];
    }

    // ÃƒÂÃ¢â‚¬â€ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â½ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ
    featureData = newFeatures;

    // 2ÃƒÂ¯Ã‚Â¸Ã‚ÂÃƒÂ¢Ã†â€™Ã‚Â£ ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‹Å“Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ AudioStateManager ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â¿Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â
    DBG("Using AudioStateManager to rebuild audio timeline...");

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‚Â¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â·ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ËœÃƒÂÃ‚Â¼ STEREO buffer!
    const int STEREO_CHANNELS = 2;
    juce::AudioBuffer<float> newAudioBuffer(STEREO_CHANNELS, newNumSamples);
    newAudioBuffer.clear();

    // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ features (ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾ÃƒÂÃ‚Â·ÃƒÂÃ‚Â´ÃƒÂÃ‚Â°ÃƒÂÃ‚Â´Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Å¡ STEREO)
    featureData.applyToAudioBuffer(newAudioBuffer, currentSampleRate);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¸ÃƒÂ ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ¢â‚¬Â¢ÃƒÂ ÃƒÂÃ…Â¡ÃƒÂÃ‚Â: ÃƒÂÃ‚Â£ÃƒÂÃ‚Â±ÃƒÂÃ‚ÂµÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¼Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚Â Ãƒâ€˜Ã¢â‚¬Â¡Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸ STEREO
    if (newAudioBuffer.getNumChannels() < 2)
    {
        DBG("ÃƒÂ¢Ã‚ÂÃ…â€™ ERROR: applyToAudioBuffer returned MONO!");
        return;
    }

    // ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â±Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Â¹
    originalSample.makeCopyOf(newAudioBuffer);
    outputBuffer.makeCopyOf(newAudioBuffer);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¡ÃƒÂ ÃƒÂÃ‹Å“ÃƒÂÃ‚Â¢ÃƒÂÃ‹Å“ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬Â¢ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ loadSample - ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¶ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Å¡ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â±Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™ STEREO!
    // ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã¢â‚¬Â¡Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â½Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â¶ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾:

    // ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ player
    samplePlayer.allNotesOff();
    samplePlayer.setSample(outputBuffer);

    // ÃƒÂ ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¦Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â¾ÃƒÂÃ‚Â² ÃƒÂÃ¢â‚¬â„¢ÃƒÂ ÃƒÂÃ‚Â£ÃƒÂÃ‚Â§ÃƒÂÃ‚ÂÃƒÂÃ‚Â£ÃƒÂÃ‚Â®
    DBG("Resynchronizing spectral indices...");
    indexDatabase.clearCache();
    indexDatabase.analyzeSample(outputBuffer, currentSampleRate);

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â€œÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ groundTruth ÃƒÂÃ‚Â² AudioStateManager ÃƒÂÃ‚Â½ÃƒÂÃ‚Â°ÃƒÂÃ‚Â¿Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¼Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã…Â½
    // (ÃƒÂÃ‚Â±ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¹ ÃƒÂÃ‚Â¿ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â·ÃƒÂÃ‚Â°ÃƒÂÃ‚Â³Ãƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â·ÃƒÂÃ‚ÂºÃƒÂÃ‚Â¸ Ãƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒÂÃ‚Â· loadSample)
    // ÃƒÂÃ‚Â­Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¶ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚Â»ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™ ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â°ÃƒÂÃ‚Â²ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â² ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â´ ÃƒÂÃ‚Â² AudioStateManager:
    // audioState.updateGroundTruth(outputBuffer);

    featuresModifiedByUser = false;
    indicesModified = false;

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Timeline region removed (STEREO preserved)!");
    DBG("===========================================");
}


bool NoiseBasedSamplerAudioProcessor::areAllIndicesSynced() const
{
    return audioState.isFullySynced();
}

void NoiseBasedSamplerAudioProcessor::forceFullResync()
{
    const juce::ScopedLock sl(sampleLock);

    DBG("ÃƒÂ°Ã…Â¸Ã¢â‚¬ÂÃ¢â‚¬Å¾ User requested FULL RESYNC");

    // ÃƒÂÃ‹Å“Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ AudioStateManager ÃƒÂÃ‚Â´ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚Â ÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â¹ Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¦Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¸
    audioState.forceFullSync(featureExtractor, indexDatabase);

    // ÃƒÂÃ‹Å“ÃƒÂÃ‚Â·ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ features ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â· ground truth
    auto groundTruth = audioState.getGroundTruthAudio();
    juce::AudioBuffer<float> monoForAnalysis(1, groundTruth.getNumSamples());
    monoForAnalysis.copyFrom(0, 0, groundTruth, 0, 0, groundTruth.getNumSamples());

    featureData = featureExtractor.extractFeatures(monoForAnalysis, currentSampleRate);

    // ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â±Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Â¹
    outputBuffer.makeCopyOf(groundTruth);
    originalSample.makeCopyOf(groundTruth);

    samplePlayer.setSample(outputBuffer);

    featuresModifiedByUser = false;
    indicesModified = false;

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ FULL RESYNC complete - all indices synchronized");
}

void NoiseBasedSamplerAudioProcessor::synthesizeFromModifiedIndices()
{
    const juce::ScopedLock sl(sampleLock);

    const auto* indices = indexDatabase.getOverviewIndices();
    if (!indices || indices->getNumFrames() == 0)
    {
        DBG("ÃƒÂ¢Ã‚ÂÃ…â€™ Cannot synthesize: no indices available");
        return;
    }

    auto modifiedBins = indices->getAllModifiedBins();
    if (modifiedBins.empty())
    {
        DBG("ÃƒÂ¢Ã…Â¡ ÃƒÂ¯Ã‚Â¸Ã‚Â No modifications detected");
        return;
    }

    DBG("===========================================");
    DBG("ÃƒÂ°Ã…Â¸Ã…Â½Ã‚Âµ APPLYING SPECTRAL CHANGES (STEREO)");
    DBG("===========================================");

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ‚ÂÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬Â¢: ÃƒÂÃ‹Å“Ãƒâ€˜Ã‚ÂÃƒÂÃ‚Â¿ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â·Ãƒâ€˜Ã†â€™ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ AudioStateManager
    audioState.applySpectralChanges(
        *indices,
        featureExtractor,
        true  // auto-sync features
    );

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ‚ÂÃƒÂÃ¢â‚¬â€œÃƒÂÃ‚ÂÃƒÂÃ…Â¾: ÃƒÂÃ…Â¸ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Â²ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ features ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â· ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â³ÃƒÂÃ‚Â¾ audio
    auto groundTruth = audioState.getGroundTruthAudio();

    // ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ ÃƒÂÃ…Â¸ÃƒÂ ÃƒÂÃ…Â¾ÃƒÂÃ¢â‚¬â„¢ÃƒÂÃ¢â‚¬Â¢ÃƒÂ ÃƒÂÃ…Â¡ÃƒÂÃ‚Â: Ground truth ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â»ÃƒÂÃ‚Â¶ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ ÃƒÂÃ‚Â±Ãƒâ€˜Ã¢â‚¬Â¹Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™ ÃƒÂÃ‚Â² STEREO
    DBG("   Ground truth channels: " + juce::String(groundTruth.getNumChannels()));

    juce::AudioBuffer<float> monoForAnalysis(1, groundTruth.getNumSamples());
    monoForAnalysis.copyFrom(0, 0, groundTruth, 0, 0, groundTruth.getNumSamples());

    // ÃƒÂÃ‹Å“ÃƒÂÃ‚Â·ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒÂÃ‚Â°ÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²Ãƒâ€˜Ã¢â‚¬Â¹ÃƒÂÃ‚Âµ features
    featureData = featureExtractor.extractFeatures(monoForAnalysis, currentSampleRate);

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Features auto-extracted from new audio");

    // ÃƒÂÃ…Â¾ÃƒÂÃ‚Â±ÃƒÂÃ‚Â½ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚Â»Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ ÃƒÂÃ‚Â±Ãƒâ€˜Ã†â€™Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã¢â‚¬Â¹
    outputBuffer.makeCopyOf(groundTruth);
    originalSample.makeCopyOf(groundTruth);

    samplePlayer.setSample(outputBuffer);

    indicesModified = false;
    featuresModifiedByUser = false;

    DBG("ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Spectral applied + Features auto-synced (STEREO)!");
    DBG("   Output channels: " + juce::String(outputBuffer.getNumChannels()));
    DBG("===========================================");
}

bool NoiseBasedSamplerAudioProcessor::areSpectralIndicesSynced() const
{
    const juce::ScopedLock sl(sampleLock);

    // ÃƒÂÃ…Â¸Ãƒâ€˜Ã¢â€šÂ¬ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â²ÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â€šÂ¬Ãƒâ€˜Ã‚ÂÃƒÂÃ‚ÂµÃƒÂÃ‚Â¼ Ãƒâ€˜Ã¢â‚¬Â¡Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â¾ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¹ ÃƒÂÃ‚Â°ÃƒÂÃ‚ÂºÃƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã†â€™ÃƒÂÃ‚Â°ÃƒÂÃ‚Â»Ãƒâ€˜Ã…â€™ÃƒÂÃ‚Â½Ãƒâ€˜Ã¢â‚¬Â¹
    const auto* indices = indexDatabase.getOverviewIndices();

    if (!indices)
        return false;

    // ÃƒÂÃ‹Å“ÃƒÂÃ‚Â½ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¹ Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¡ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¡ÃƒÂÃ‚Â°Ãƒâ€˜Ã…Â½Ãƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã‚Â synced ÃƒÂÃ‚ÂµÃƒâ€˜Ã‚ÂÃƒÂÃ‚Â»ÃƒÂÃ‚Â¸:
    // 1. ÃƒÂÃ¢â‚¬Â¢Ãƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Å¡Ãƒâ€˜Ã…â€™ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â½ÃƒÂÃ‚Â´ÃƒÂÃ‚ÂµÃƒÂÃ‚ÂºÃƒâ€˜Ã‚ÂÃƒâ€˜Ã¢â‚¬Â¹
    // 2. ÃƒÂÃ‚ÂÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Å¡ pending feature ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â·ÃƒÂÃ‚Â¼ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚ÂµÃƒÂÃ‚Â½ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¹
    // 3. ÃƒÂÃ‚ÂÃƒÂÃ‚ÂµÃƒâ€˜Ã¢â‚¬Å¡ spectral ÃƒÂÃ‚Â¼ÃƒÂÃ‚Â¾ÃƒÂÃ‚Â´ÃƒÂÃ‚Â¸Ãƒâ€˜Ã¢â‚¬Å¾ÃƒÂÃ‚Â¸ÃƒÂÃ‚ÂºÃƒÂÃ‚Â°Ãƒâ€˜Ã¢â‚¬ ÃƒÂÃ‚Â¸ÃƒÂÃ‚Â¹

    return !featuresModifiedByUser && !indicesModified;
}

NoiseBasedSamplerAudioProcessor::ModificationStatistics
NoiseBasedSamplerAudioProcessor::getModificationStatistics() const
{
    const juce::ScopedLock sl(sampleLock);
    ModificationStatistics stats;

    const auto* indices = indexDatabase.getOverviewIndices();
    if (!indices)
        return stats;

    auto modifiedBins = indices->getAllModifiedBins();
    stats.totalModifiedBins = static_cast<int>(modifiedBins.size());

    if (modifiedBins.empty())
        return stats;

    std::set<int> uniqueFrames;
    for (const auto& binInfo : modifiedBins)
    {
        uniqueFrames.insert(binInfo.frameIdx);
    }
    stats.totalModifiedFrames = static_cast<int>(uniqueFrames.size());

    stats.minModifiedFreq = modifiedBins[0].frequency;
    stats.maxModifiedFreq = modifiedBins[0].frequency;

    for (const auto& binInfo : modifiedBins)
    {
        stats.minModifiedFreq = juce::jmin(stats.minModifiedFreq, binInfo.frequency);
        stats.maxModifiedFreq = juce::jmax(stats.maxModifiedFreq, binInfo.frequency);

        float time = indices->getFrame(binInfo.frameIdx).timePosition;
        if (binInfo.frameIdx == modifiedBins[0].frameIdx)
        {
            stats.minModifiedTime = time;
            stats.maxModifiedTime = time;
        }
        else
        {
            stats.minModifiedTime = juce::jmin(stats.minModifiedTime, time);
            stats.maxModifiedTime = juce::jmax(stats.maxModifiedTime, time);
        }
    }

    return stats;
}

// ğŸ”Š REAL-TIME EFFECTS PROCESSING
void NoiseBasedSamplerAudioProcessor::applyRealtimeEffects(juce::AudioBuffer<float>& buffer)
{
    if (buffer.getNumSamples() == 0 || buffer.getNumChannels() == 0)
        return;

    const int numSamples = buffer.getNumSamples();
    const int numChannels = buffer.getNumChannels();

    // DEBUG: Check if function is being called and sample is loaded
    static bool firstCall = true;
    if (firstCall)
    {
        DBG("ğŸ”Š applyRealtimeEffects called! Samples: " + juce::String(numSamples) + " Channels: " + juce::String(numChannels));
        DBG("ğŸ”Š Sample loaded: " + juce::String(sampleLoaded ? "YES" : "NO"));
        if (sampleLoaded)
        {
            DBG("ğŸ”Š Original sample length: " + juce::String(originalSample.getNumSamples()));
        }
        firstCall = false;
    }

    // Only apply effects if we have audio data
    if (!sampleLoaded)
        return;

    // 1. BOOST/GAIN
    float boostDb = getBoostDb();
    if (std::abs(boostDb) > 0.01f)
    {
        float boostGain = juce::Decibels::decibelsToGain(boostDb);
        buffer.applyGain(boostGain);
        DBG("ğŸ”Š BOOST APPLIED: " + juce::String(boostDb, 1) + "dB (gain: " + juce::String(boostGain, 2) + ")");
    }

    // 2. PITCH SHIFT
    float pitchShiftSemitones = getPitchShift();
    if (std::abs(pitchShiftSemitones) > 0.01f)
    {
        float pitchRatio = std::pow(2.0f, pitchShiftSemitones / 12.0f);

        // Simple pitch shifting using resampling
        for (int ch = 0; ch < numChannels; ++ch)
        {
            const auto* channelData = buffer.getReadPointer(ch);
            auto* outputData = buffer.getWritePointer(ch);

            // Create temporary buffer for pitch shifted audio
            juce::AudioBuffer<float> pitchBuffer(1, numSamples);
            auto* pitchData = pitchBuffer.getWritePointer(0);

            // Simple resampling pitch shift
            for (int i = 0; i < numSamples; ++i)
            {
                float sourcePos = i / pitchRatio;
                int sourceIndex = static_cast<int>(sourcePos);
                float fraction = sourcePos - sourceIndex;

                if (sourceIndex < numSamples - 1)
                {
                    float sample1 = channelData[sourceIndex];
                    float sample2 = channelData[sourceIndex + 1];
                    pitchData[i] = sample1 + fraction * (sample2 - sample1);
                }
                else
                {
                    pitchData[i] = 0.0f; // Pad with silence
                }
            }

            // Copy back directly to the channel
            std::copy(pitchData, pitchData + numSamples, outputData);
        }
    }

    // 3. TIME STRETCH
    float timeStretchRatio = getTimeStretch();
    if (std::abs(timeStretchRatio - 1.0f) > 0.01f)
    {
        // Simple time stretching using overlap-add
        for (int ch = 0; ch < numChannels; ++ch)
        {
            const auto* channelData = buffer.getReadPointer(ch);
            auto* outputData = buffer.getWritePointer(ch);

            // Create temporary buffer for time stretched audio
            juce::AudioBuffer<float> stretchBuffer(1, numSamples);
            auto* stretchData = stretchBuffer.getWritePointer(0);

            if (timeStretchRatio > 1.0f) // Slow down
            {
                for (int i = 0; i < numSamples; ++i)
                {
                    float sourcePos = i / timeStretchRatio;
                    int sourceIndex = static_cast<int>(sourcePos);
                    float fraction = sourcePos - sourceIndex;

                    if (sourceIndex < numSamples - 1)
                    {
                        float sample1 = channelData[sourceIndex];
                        float sample2 = channelData[sourceIndex + 1];
                        stretchData[i] = sample1 + fraction * (sample2 - sample1);
                    }
                    else
                    {
                        stretchData[i] = channelData[std::min(sourceIndex, numSamples - 1)];
                    }
                }
            }
            else // Speed up
            {
                for (int i = 0; i < numSamples; ++i)
                {
                    float sourcePos = i * timeStretchRatio;
                    int sourceIndex = static_cast<int>(sourcePos);
                    stretchData[i] = sourceIndex < numSamples ? channelData[sourceIndex] : 0.0f;
                }
            }

            // Copy back directly to the channel
            std::copy(stretchData, stretchData + numSamples, outputData);
        }
    }

    // 4. LOOP HANDLING (basic implementation)
    if (isLoopActive())
    {
        // For now, just log that loop is active
        // Full loop implementation would requireSamplePlayer integration
        DBG("ğŸ”„ Loop active (basic implementation)");
    }
}

juce::AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new NoiseBasedSamplerAudioProcessor();
}